{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/frhack/oli_ai/blob/main/notebooks/oli_ai_mnist_cosine_similarity.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE-Gc2QdS-Qp"
      },
      "source": [
        "# MNIST - Riconoscimento di cifre con il metodo della similarità coseno\n",
        "\n",
        "Questo notebook mostra come riconoscere cifre scritte a mano usando un semplice metodo basato sulla similarità coseno. Utilizzeremo il famoso dataset MNIST che contiene 70.000 immagini di cifre scritte a mano (da 0 a 9).\n",
        "\n",
        "## Formato delle immagini digitali\n",
        "\n",
        "Nel dataset MNIST, ogni immagine è rappresentata come una matrice di 28×28 pixel (totale 784 pixel). Ogni pixel contiene un valore numerico che rappresenta l'intensità di grigio:\n",
        "- 0 rappresenta il bianco\n",
        "- 255 rappresenta il nero\n",
        "- I valori intermedi sono diverse tonalità di grigio\n",
        "\n",
        "Quando elaboriamo queste immagini, possiamo:\n",
        "1. Lavorare con la matrice 28×28 (utile per visualizzazione)\n",
        "2. \"Appiattire\" l'immagine in un vettore di 784 elementi (utile per calcoli matematici)\n",
        "\n",
        "## Train set e Test set: Perché dividiamo i dati?\n",
        "\n",
        "Nel machine learning, dividiamo sempre i dati in almeno due gruppi:\n",
        "- **Train set (dati di addestramento)**: Usato per insegnare al modello. Nel nostro caso, useremo questi dati per calcolare le immagini medie di ogni cifra.\n",
        "- **Test set (dati di test)**: Usato per valutare quanto bene il modello generalizza su dati mai visti prima.\n",
        "\n",
        "Questa divisione è fondamentale perché vogliamo verificare che il modello funzioni bene su dati nuovi e non semplicemente \"memorizzi\" i dati di addestramento. Nel dataset MNIST, i dati sono già divisi in:\n",
        "- 60.000 immagini di addestramento\n",
        "- 10.000 immagini di test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importazione delle librerie necessarie\n",
        "\n",
        "Le seguenti librerie sono necessarie per l'elaborazione dei dati, la visualizzazione e i calcoli matematici."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#installo modulo oli_ai\n",
        "!pip install --upgrade --no-cache-dir oli_ai > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvZic-4NX1iq"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from oli_ai.mnist_lib import *\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from numpy import dot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esplorazione dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = mnist.load_data()\n",
        "(X_train, y_train), (X_test, y_test) = data\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(X_train[0].shape)\n",
        "print(y_train[0])  \n",
        "#X_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizzazione di una cifra\n",
        "\n",
        "Qui visualizziamo la prima immagine dal set di addestramento per capire come appare una cifra.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTQk9YCDXIsB",
        "outputId": "8bd2c8a5-8d9c-4dcc-ff0e-c4d054db0913"
      },
      "outputs": [],
      "source": [
        "\n",
        "plot_imgs_labels(X_train,y_train, 3, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizzazione di più cifre con le loro etichette e dei pixel\n",
        "\n",
        "Questa visualizzazione mostra diverse cifre con le loro etichette, permettendoci di capire la varietà di stili di scrittura presenti nel dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "immagine_0 = X_train[0] \n",
        "plot_img(immagine_0)\n",
        "\n",
        "print(immagine_0[0][0])\n",
        "print(immagine_0[6][12])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifre_5 = X_train[y_train==5]\n",
        "media_cifra_5 = np.average(X_train[y_train==5],0)\n",
        "\n",
        "plot_img(media_cifra_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fase 1: Apprendimento (Training)\n",
        "\n",
        "Durante la fase di apprendimento, il modello \"impara\" dai dati di addestramento. Nel nostro caso, il modello è molto semplice:\n",
        "\n",
        "1. Per ogni cifra (0-9), calcoliamo un'\"immagine media\" usando tutti gli esempi di quella cifra nel set di addestramento\n",
        "2. Queste 10 immagini medie diventano il nostro \"modello\" - rappresentano come appare tipicamente ogni cifra\n",
        "\n",
        "Questo è un esempio di apprendimento supervisionato, perché usiamo le etichette (y_train) per guidare l'apprendimento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifre_medie = [np.average(X_train[y_train==i],0) for i in range(10)]\n",
        "# = np.array(avgs)\n",
        "#avgs = avgs.reshape((avgs.shape[0], 28*28)).astype('float32')\n",
        "\n",
        "plot_imgs_labels(cifre_medie,range(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definizione della similarità coseno e della funzione di predizione\n",
        "\n",
        "La similarità coseno è una misura matematica che indica quanto sono simili due vettori. Varia da -1 (completamente opposti) a 1 (identici). È calcolata come il prodotto scalare dei vettori normalizzati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sim(vettore1,vettore2):\n",
        "    vettore1_unitario = vettore1/norm(vettore1)\n",
        "    vettore2_unitario = vettore2/norm(vettore2)\n",
        "    similitudine = dot(vettore1_unitario,vettore2_unitario)\n",
        "    return  similitudine\n",
        "\n",
        "\n",
        "# ritorna l'indice del vettore più simile a vettore tra quelli in vettori\n",
        "def argmax_sim(vettore, vettori):\n",
        "    num_vettori = len(vettori)\n",
        "    similitudini = np.zeros(num_vettori)\n",
        "    for i in range(num_vettori):\n",
        "        similitudini[i] = sim(vettore,vettori[i])\n",
        "    return np.argmax(similitudini)\n",
        "\n",
        "\n",
        "def predizione(image, cifre_medie):\n",
        "    vettore = image.reshape((28*28,))\n",
        "    vettori = [image.reshape((28*28,)) for image in cifre_medie]\n",
        "    return argmax_sim(vettore,vettori)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fase 2: Inferenza (Predizione)\n",
        "\n",
        "Durante la fase di inferenza, usiamo il modello addestrato (le immagini medie) per fare previsioni su nuovi dati:\n",
        "\n",
        "1. Per ogni nuova immagine, calcoliamo la similarità coseno con ciascuna delle 10 immagini medie\n",
        "2. Assegniamo all'immagine la cifra corrispondente all'immagine media più simile\n",
        "\n",
        "Questo è il momento in cui il modello \"lavora\" su dati mai visti prima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predizioni = [predizione(x,cifre_medie) for x in X_test]\n",
        "\n",
        "plot_imgs_labels(X_test,predizioni,3,5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predizione_immagine_50 = predizione(X_test[50],cifre_medie)\n",
        "plot_img(X_test[50])\n",
        "print(f\"Valore predetto: {predizione_immagine_50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Valutazione del modello\n",
        "\n",
        "Dopo aver fatto predizioni su tutte le immagini di test, possiamo calcolare l'accuratezza del nostro modello. L'accuratezza è semplicemente la percentuale di immagini classificate correttamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vettore_esiti_booleani = predizioni == y_test\n",
        "\n",
        "accuracy = vettore_esiti_booleani.sum()/len(vettore_esiti_booleani)\n",
        "\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parametri del modello\n",
        "\n",
        "Un aspetto fondamentale in machine learning è capire quanti \"parametri\" (o \"pesi\") ha il nostro modello. I parametri sono i valori che il modello apprende durante la fase di addestramento.\n",
        "\n",
        "Nel nostro modello:\n",
        "- Ogni immagine media è una matrice 28×28 (o equivalentemente un vettore di 784 elementi)\n",
        "- Abbiamo 10 immagini medie (una per cifra)\n",
        "- Quindi, abbiamo un totale di 10 × 784 = 7.840 parametri\n",
        "\n",
        "Confrontiamo questo con altri modelli:\n",
        "- Una rete neurale convoluzionale moderna per MNIST potrebbe avere centinaia di migliaia di parametri\n",
        "- Modelli di deep learning per problemi complessi possono avere milioni o miliardi di parametri\n",
        "\n",
        "Il nostro modello è estremamente semplice, ma ottiene comunque un'accuratezza dell'82% circa. Questo è un buon esempio di come a volte approcci semplici possano dare risultati sorprendentemente buoni!\n",
        "\n",
        "## Conclusioni\n",
        "\n",
        "Abbiamo costruito un classificatore di cifre scritte a mano che raggiunge circa l'82% di accuratezza usando solo la similarità coseno e le immagini medie. È un risultato notevole considerando la semplicità del metodo!\n",
        "\n",
        "Questo approccio è un esempio di \"apprendimento basato su modello\": abbiamo creato un modello (le immagini medie) per ogni cifra e poi abbiamo classificato nuove immagini confrontandole con questi modelli.\n",
        "\n",
        "Metodi più avanzati come le reti neurali possono raggiungere un'accuratezza superiore al 99% su questo dataset, ma richiedono maggiore complessità computazionale.\n",
        "\n",
        "## Esercizi e attività\n",
        "\n",
        "1. Visualizza alcune immagini che sono state classificate in modo errato. Puoi capire perché?\n",
        "2. Calcola la matrice di confusione per vedere quali cifre vengono confuse più frequentemente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matrice di Confusione per il Classificatore MNIST con Similarità Coseno\n",
        "\n",
        "\n",
        "## Spiegazione della Matrice di Confusione\n",
        "\n",
        "La matrice di confusione è uno strumento fondamentale per valutare le prestazioni di un modello di classificazione. \n",
        "Essa mostra non solo quante previsioni sono state corrette, ma anche quali classi vengono confuse tra loro.\n",
        "Vediamo come interpretarla e perché è importante nel contesto del riconoscimento delle cifre MNIST.\n",
        "\n",
        "### Cos'è una Matrice di Confusione?\n",
        "\n",
        "Una matrice di confusione è una tabella che mostra la distribuzione delle previsioni rispetto ai valori reali. In una matrice di confusione:\n",
        "\n",
        "- Le righe rappresentano i valori reali (le vere cifre)\n",
        "- Le colonne rappresentano i valori predetti dal modello\n",
        "- Ogni cella (i,j) contiene il numero di esempi della classe i che sono stati classificati come classe j\n",
        "\n",
        "### Perché È Utile?\n",
        "\n",
        "La matrice di confusione ci permette di:\n",
        "\n",
        "1. Vedere non solo quante classificazioni sono corrette (sulla diagonale), ma anche quali classi vengono confuse tra loro\n",
        "2. Identificare pattern sistematici di errore\n",
        "3. Riconoscere le cifre più problematiche da classificare\n",
        "\n",
        "### Interpretazione dei Risultati\n",
        "\n",
        "\n",
        "1. La matrice di confusione grezza (conteggi)\n",
        "2. La matrice normalizzata (percentuali)\n",
        "3. Un'analisi delle confusioni più frequenti\n",
        "4. Un elenco delle cifre ordinate dalla più difficile alla più facile da classificare\n",
        "5. Esempi visivi di errori comuni\n",
        "\n",
        "Quando esegui il codice, noterai probabilmente questi pattern:\n",
        "\n",
        "- Alcune cifre come l'8 tendono a essere confuse più frequentemente con altre (ad esempio il 3 o il 5)\n",
        "- Cifre con forma simile come 3 e 5, o 4 e 9, si confondono spesso tra loro\n",
        "- Alcune cifre sono più facili da riconoscere di altre, probabilmente perché hanno forme più distintive\n",
        "\n",
        "## Conclusione\n",
        "\n",
        "La matrice di confusione ci offre una visione molto più dettagliata delle prestazioni del nostro modello rispetto alla semplice accuratezza. Ci permette di capire quali cifre sono più problematiche e quali vengono confuse tra loro.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predizioni)\n",
        "\n",
        "# Visualizzazione della matrice di confusione\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel('Previsione')\n",
        "plt.ylabel('Valore Reale')\n",
        "plt.title('Matrice di Confusione')\n",
        "plt.show()\n",
        "\n",
        "# Calcolo delle percentuali di confusione\n",
        "# Normalizzazione per riga (per ogni cifra reale, dove vanno le previsioni)\n",
        "conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix_norm, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel('Previsione')\n",
        "plt.ylabel('Valore Reale')\n",
        "plt.title('Matrice di Confusione (Normalizzata)')\n",
        "plt.show()\n",
        "\n",
        "# Analisi delle confusioni più frequenti\n",
        "print(\"\\nAnalisi delle confusioni più frequenti:\")\n",
        "for i in range(10):\n",
        "    # Escludiamo la diagonale principale (predizioni corrette)\n",
        "    mask = np.ones(10, dtype=bool)\n",
        "    mask[i] = False\n",
        "    confuso_con = np.argmax(conf_matrix[i, mask])\n",
        "    # Aggiusta l'indice se necessario\n",
        "    if confuso_con >= i:\n",
        "        confuso_con += 1\n",
        "    perc_confusione = conf_matrix[i, confuso_con] / conf_matrix[i, :].sum() * 100\n",
        "    print(f\"Cifra {i} confusa più frequentemente con {confuso_con} ({perc_confusione:.1f}% delle volte)\")\n",
        "\n",
        "# Calcolo delle cifre più difficili da classificare\n",
        "accuratezza_per_cifra = np.diag(conf_matrix) / conf_matrix.sum(axis=1)\n",
        "cifre_ordinate = np.argsort(accuratezza_per_cifra)\n",
        "\n",
        "print(\"\\nCifre ordinate dalla più difficile alla più facile da classificare:\")\n",
        "for cifra in cifre_ordinate:\n",
        "    print(f\"Cifra {cifra}: accuratezza {accuratezza_per_cifra[cifra]:.4f} ({accuratezza_per_cifra[cifra]*100:.1f}%)\")\n",
        "\n",
        "# Visualizziamo alcuni esempi di errori per le confusioni più frequenti\n",
        "def trova_errori(y_test, predizioni, cifra_reale, cifra_predetta, num_esempi=5):\n",
        "    \"\"\"Trova esempi dove cifra_reale è stata classificata erroneamente come cifra_predetta.\"\"\"\n",
        "    indici = np.where((y_test == cifra_reale) & (predizioni == cifra_predetta))[0]\n",
        "    return indici[:num_esempi]\n",
        "\n",
        "# Troviamo le confusioni più frequenti\n",
        "confusioni = []\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        if i != j:  # Escludiamo la diagonale principale\n",
        "            confusioni.append((i, j, conf_matrix[i, j]))\n",
        "\n",
        "# Ordiniamo per frequenza\n",
        "confusioni.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "print(\"\\nVisualizzazione di alcuni esempi delle confusioni più frequenti:\")\n",
        "for reale, predetta, conteggio in confusioni[:3]:  # Consideriamo le 3 confusioni più frequenti\n",
        "    print(f\"\\nEsempi di cifra {reale} classificata come {predetta} (occorre {conteggio} volte):\")\n",
        "    indici_errori = trova_errori(y_test, predizioni, reale, predetta)\n",
        "    if len(indici_errori) > 0:\n",
        "        errori_imgs = [X_test[i] for i in indici_errori]\n",
        "        plot_imgs_labels(errori_imgs, [f\"Real: {reale}, Pred: {predetta}\"] * len(errori_imgs), \n",
        "                        rows=1, cols=min(5, len(errori_imgs)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
