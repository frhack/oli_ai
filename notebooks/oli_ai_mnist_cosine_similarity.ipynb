{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/frhack/oli_ai/blob/main/notebooks/oli_ai_mnist_cosine_similarity.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE-Gc2QdS-Qp"
      },
      "source": [
        "# MNIST - Riconoscimento di cifre con il metodo della similarità coseno\n",
        "\n",
        "Questo notebook mostra come riconoscere cifre scritte a mano usando un semplice metodo basato sulla similarità coseno. Utilizzeremo il famoso dataset MNIST che contiene 70.000 immagini di cifre scritte a mano (da 0 a 9).\n",
        "\n",
        "## Formato delle immagini digitali\n",
        "\n",
        "Nel dataset MNIST, ogni immagine è rappresentata come una matrice di 28×28 pixel (totale 784 pixel). Ogni pixel contiene un valore numerico che rappresenta l'intensità di grigio:\n",
        "- 0 rappresenta il bianco\n",
        "- 255 rappresenta il nero\n",
        "- I valori intermedi sono diverse tonalità di grigio\n",
        "\n",
        "Quando elaboriamo queste immagini, possiamo:\n",
        "1. Lavorare con la matrice 28×28 (utile per visualizzazione)\n",
        "2. \"Appiattire\" l'immagine in un vettore di 784 elementi (utile per calcoli matematici)\n",
        "\n",
        "## Train set e Test set: Perché dividiamo i dati?\n",
        "\n",
        "Nel machine learning, dividiamo sempre i dati in almeno due gruppi:\n",
        "- **Train set (dati di addestramento)**: Usato per insegnare al modello. Nel nostro caso, useremo questi dati per calcolare le immagini medie di ogni cifra.\n",
        "- **Test set (dati di test)**: Usato per valutare quanto bene il modello generalizza su dati mai visti prima.\n",
        "\n",
        "Questa divisione è fondamentale perché vogliamo verificare che il modello funzioni bene su dati nuovi e non semplicemente \"memorizzi\" i dati di addestramento. Nel dataset MNIST, i dati sono già divisi in:\n",
        "- 60.000 immagini di addestramento\n",
        "- 10.000 immagini di test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir oli_ai > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvZic-4NX1iq"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from oli_ai.mnist_lib import *\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from numpy import dot\n",
        "\n",
        "data = mnist.load_data()\n",
        "(X_train, y_train), (X_test, y_test) = data\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(X_train[0].shape)\n",
        "print(y_train[0])  \n",
        "#X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTQk9YCDXIsB",
        "outputId": "8bd2c8a5-8d9c-4dcc-ff0e-c4d054db0913"
      },
      "outputs": [],
      "source": [
        "\n",
        "plot_imgs_labels(X_train,y_train, 3, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "immagine_0 = X_train[0] \n",
        "plot_img(immagine_0)\n",
        "\n",
        "print(immagine_0[0][0])\n",
        "print(immagine_0[6][12])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifre_5 = X_train[y_train==5]\n",
        "media_cifra_5 = np.average(X_train[y_train==5],0)\n",
        "\n",
        "plot_img(media_cifra_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fase 1: Apprendimento (Training)\n",
        "\n",
        "Durante la fase di apprendimento, il modello \"impara\" dai dati di addestramento. Nel nostro caso, il modello è molto semplice:\n",
        "\n",
        "1. Per ogni cifra (0-9), calcoliamo un'\"immagine media\" usando tutti gli esempi di quella cifra nel set di addestramento\n",
        "2. Queste 10 immagini medie diventano il nostro \"modello\" - rappresentano come appare tipicamente ogni cifra\n",
        "\n",
        "Questo è un esempio di apprendimento supervisionato, perché usiamo le etichette (y_train) per guidare l'apprendimento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifre_medie = [np.average(X_train[y_train==i],0) for i in range(10)]\n",
        "# = np.array(avgs)\n",
        "#avgs = avgs.reshape((avgs.shape[0], 28*28)).astype('float32')\n",
        "\n",
        "plot_imgs_labels(cifre_medie,range(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sim(vettore1,vettore2):\n",
        "    vettore1_unitario = vettore1/norm(vettore1)\n",
        "    vettore2_unitario = vettore2/norm(vettore2)\n",
        "    similitudine = dot(vettore1_unitario,vettore2_unitario)\n",
        "    return  similitudine\n",
        "\n",
        "\n",
        "# ritorna l'indice del vettore più simile a vettore tra quelli in vettori\n",
        "def argmax_sim(vettore, vettori):\n",
        "    num_vettori = len(vettori)\n",
        "    similitudini = np.zeros(num_vettori)\n",
        "    for i in range(num_vettori):\n",
        "        similitudini[i] = sim(vettore,vettori[i])\n",
        "    return np.argmax(similitudini)\n",
        "\n",
        "\n",
        "def predizione(image, cifre_medie):\n",
        "    vettore = image.reshape((28*28,))\n",
        "    vettori = [image.reshape((28*28,)) for image in cifre_medie]\n",
        "    return argmax_sim(vettore,vettori)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fase 2: Inferenza (Predizione)\n",
        "\n",
        "Durante la fase di inferenza, usiamo il modello addestrato (le immagini medie) per fare previsioni su nuovi dati:\n",
        "\n",
        "1. Per ogni nuova immagine, calcoliamo la similarità coseno con ciascuna delle 10 immagini medie\n",
        "2. Assegniamo all'immagine la cifra corrispondente all'immagine media più simile\n",
        "\n",
        "Questo è il momento in cui il modello \"lavora\" su dati mai visti prima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predizioni = [predizione(x,cifre_medie) for x in X_test]\n",
        "\n",
        "plot_imgs_labels(X_test,predizioni,3,5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predizione_immagine_50 = predizione(X_test[50],cifre_medie)\n",
        "plot_img(X_test[50])\n",
        "print(f\"Valore predetto: {predizione_immagine_50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Valutazione del modello\n",
        "\n",
        "Dopo aver fatto predizioni su tutte le immagini di test, possiamo calcolare l'accuratezza del nostro modello. L'accuratezza è semplicemente la percentuale di immagini classificate correttamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vettore_esiti_booleani = predizioni == y_test\n",
        "\n",
        "accuracy = vettore_esiti_booleani.sum()/len(vettore_esiti_booleani)\n",
        "\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parametri del modello\n",
        "\n",
        "Un aspetto fondamentale in machine learning è capire quanti \"parametri\" (o \"pesi\") ha il nostro modello. I parametri sono i valori che il modello apprende durante la fase di addestramento.\n",
        "\n",
        "Nel nostro modello:\n",
        "- Ogni immagine media è una matrice 28×28 (o equivalentemente un vettore di 784 elementi)\n",
        "- Abbiamo 10 immagini medie (una per cifra)\n",
        "- Quindi, abbiamo un totale di 10 × 784 = 7.840 parametri\n",
        "\n",
        "Confrontiamo questo con altri modelli:\n",
        "- Una rete neurale convoluzionale moderna per MNIST potrebbe avere centinaia di migliaia di parametri\n",
        "- Modelli di deep learning per problemi complessi possono avere milioni o miliardi di parametri\n",
        "\n",
        "Il nostro modello è estremamente semplice, ma ottiene comunque un'accuratezza dell'82% circa. Questo è un buon esempio di come a volte approcci semplici possano dare risultati sorprendentemente buoni!\n",
        "\n",
        "## Conclusioni\n",
        "\n",
        "Abbiamo costruito un classificatore di cifre scritte a mano che raggiunge circa l'82% di accuratezza usando solo la similarità coseno e le immagini medie. È un risultato notevole considerando la semplicità del metodo!\n",
        "\n",
        "Questo approccio è un esempio di \"apprendimento basato su modello\": abbiamo creato un modello (le immagini medie) per ogni cifra e poi abbiamo classificato nuove immagini confrontandole con questi modelli.\n",
        "\n",
        "Metodi più avanzati come le reti neurali possono raggiungere un'accuratezza superiore al 99% su questo dataset, ma richiedono maggiore complessità computazionale.\n",
        "\n",
        "## Esercizi e attività\n",
        "\n",
        "1. Visualizza alcune immagini che sono state classificate in modo errato. Puoi capire perché?\n",
        "2. Calcola la matrice di confusione per vedere quali cifre vengono confuse più frequentemente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Importazione delle librerie necessarie\n",
        "\n",
        "Le seguenti librerie sono necessarie per l'elaborazione dei dati, la visualizzazione e i calcoli matematici.\n",
        "\n",
        "```python\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from oli_ai.mnist_lib import *\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from numpy import dot\n",
        "```\n",
        "\n",
        "## Caricamento del dataset MNIST\n",
        "\n",
        "Carichiamo il dataset MNIST, che viene diviso in dati di addestramento (X_train, y_train) e dati di test (X_test, y_test).\n",
        "\n",
        "```python\n",
        "data = mnist.load_data()\n",
        "(X_train, y_train), (X_test, y_test) = data\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(X_train[0].shape)\n",
        "print(y_train[0])  \n",
        "#X_train.shape\n",
        "```\n",
        "\n",
        "## Visualizzazione di una cifra\n",
        "\n",
        "Qui visualizziamo la prima immagine dal set di addestramento per capire come appare una cifra.\n",
        "\n",
        "```python\n",
        "plot_img(X_train[0])\n",
        "```\n",
        "\n",
        "## Visualizzazione di più cifre con le loro etichette\n",
        "\n",
        "Questa visualizzazione mostra diverse cifre con le loro etichette, permettendoci di capire la varietà di stili di scrittura presenti nel dataset.\n",
        "\n",
        "```python\n",
        "plot_imgs_labels(X_train,y_train, 3, 10)\n",
        "```\n",
        "\n",
        "## Fase 1: Apprendimento (Training)\n",
        "\n",
        "Durante la fase di apprendimento, il modello \"impara\" dai dati di addestramento. Nel nostro caso, il modello è molto semplice:\n",
        "\n",
        "1. Per ogni cifra (0-9), calcoliamo un'\"immagine media\" usando tutti gli esempi di quella cifra nel set di addestramento\n",
        "2. Queste 10 immagini medie diventano il nostro \"modello\" - rappresentano come appare tipicamente ogni cifra\n",
        "\n",
        "Questo è un esempio di apprendimento supervisionato, perché usiamo le etichette (y_train) per guidare l'apprendimento.\n",
        "\n",
        "```python\n",
        "cifre_5 = X_train[y_train==5]\n",
        "media_cifra_5 = np.average(X_train[y_train==5],0)\n",
        "\n",
        "plot_img(media_cifra_5)\n",
        "```\n",
        "\n",
        "## Visualizzazione di tutte le immagini medie\n",
        "\n",
        "Ecco le immagini medie per tutte le cifre da 0 a 9. Questi sono i \"prototipi\" che il nostro modello utilizzerà per riconoscere nuove cifre.\n",
        "\n",
        "```python\n",
        "cifre_medie = [np.average(X_train[y_train==i],0) for i in range(10)]\n",
        "# = np.array(avgs)\n",
        "#avgs = avgs.reshape((avgs.shape[0], 28*28)).astype('float32')\n",
        "\n",
        "plot_imgs_labels(cifre_medie,range(10))\n",
        "```\n",
        "\n",
        "## Definizione della similarità coseno\n",
        "\n",
        "La similarità coseno è una misura matematica che indica quanto sono simili due vettori. Varia da -1 (completamente opposti) a 1 (identici). È calcolata come il prodotto scalare dei vettori normalizzati.\n",
        "\n",
        "La funzione `sim()` calcola la similarità coseno tra due vettori.\n",
        "\n",
        "```python\n",
        "def sim(vettore1,vettore2):\n",
        "    vettore1_unitario = vettore1/norm(vettore1)\n",
        "    vettore2_unitario = vettore2/norm(vettore2)\n",
        "    similitudine = dot(vettore1_unitario,vettore2_unitario)\n",
        "    return  similitudine\n",
        "\n",
        "\n",
        "# ritorna l'indice del vettore più simile a vettore tra quelli in vettori\n",
        "def argmax_sim(vettore, vettori):\n",
        "    num_vettori = len(vettori)\n",
        "    similitudini = np.zeros(num_vettori)\n",
        "    for i in range(num_vettori):\n",
        "        similitudini[i] = sim(vettore,vettori[i])\n",
        "    return np.argmax(similitudini)\n",
        "\n",
        "\n",
        "def predizione(image, cifre_medie):\n",
        "    vettore = image.reshape((28*28,))\n",
        "    vettori = [image.reshape((28*28,)) for image in cifre_medie]\n",
        "    return argmax_sim(vettore,vettori)\n",
        "```\n",
        "\n",
        "## Fase 2: Inferenza (Predizione)\n",
        "\n",
        "Durante la fase di inferenza, usiamo il modello addestrato (le immagini medie) per fare previsioni su nuovi dati:\n",
        "\n",
        "1. Per ogni nuova immagine, calcoliamo la similarità coseno con ciascuna delle 10 immagini medie\n",
        "2. Assegniamo all'immagine la cifra corrispondente all'immagine media più simile\n",
        "\n",
        "Questo è il momento in cui il modello \"lavora\" su dati mai visti prima.\n",
        "\n",
        "```python\n",
        "predizioni = [predizione(x,cifre_medie) for x in X_test]\n",
        "\n",
        "plot_imgs_labels(X_test,predizioni,3,5)\n",
        "```\n",
        "\n",
        "## Valutazione del modello\n",
        "\n",
        "Dopo aver fatto predizioni su tutte le immagini di test, possiamo calcolare l'accuratezza del nostro modello. L'accuratezza è semplicemente la percentuale di immagini classificate correttamente.\n",
        "\n",
        "```python\n",
        "vettore_esiti_booleani = predizioni == y_test\n",
        "\n",
        "accuracy = vettore_esiti_booleani.sum()/len(vettore_esiti_booleani)\n",
        "\n",
        "print(accuracy)\n",
        "```\n",
        "\n",
        "## Parametri del modello\n",
        "\n",
        "Un aspetto fondamentale in machine learning è capire quanti \"parametri\" (o \"pesi\") ha il nostro modello. I parametri sono i valori che il modello apprende durante la fase di addestramento.\n",
        "\n",
        "Nel nostro modello:\n",
        "- Ogni immagine media è una matrice 28×28 (o equivalentemente un vettore di 784 elementi)\n",
        "- Abbiamo 10 immagini medie (una per cifra)\n",
        "- Quindi, abbiamo un totale di 10 × 784 = 7.840 parametri\n",
        "\n",
        "Confrontiamo questo con altri modelli:\n",
        "- Una rete neurale convoluzionale moderna per MNIST potrebbe avere centinaia di migliaia di parametri\n",
        "- Modelli di deep learning per problemi complessi possono avere milioni o miliardi di parametri\n",
        "\n",
        "Il nostro modello è estremamente semplice, ma ottiene comunque un'accuratezza dell'82% circa. Questo è un buon esempio di come a volte approcci semplici possano dare risultati sorprendentemente buoni!\n",
        "\n",
        "## Conclusioni\n",
        "\n",
        "Abbiamo costruito un classificatore di cifre scritte a mano che raggiunge circa l'82% di accuratezza usando solo la similarità coseno e le immagini medie. È un risultato notevole considerando la semplicità del metodo!\n",
        "\n",
        "Questo approccio è un esempio di \"apprendimento basato su modello\": abbiamo creato un modello (le immagini medie) per ogni cifra e poi abbiamo classificato nuove immagini confrontandole con questi modelli.\n",
        "\n",
        "Metodi più avanzati come le reti neurali possono raggiungere un'accuratezza superiore al 99% su questo dataset, ma richiedono maggiore complessità computazionale.\n",
        "\n",
        "## Esercizi e attività\n",
        "\n",
        "1. Prova a modificare la funzione di similarità e vedi se puoi migliorare l'accuratezza.\n",
        "2. Visualizza alcune immagini che sono state classificate in modo errato. Puoi capire perché?\n",
        "3. Come potremmo migliorare questo approccio semplice?\n",
        "4. Calcola la matrice di confusione per vedere quali cifre vengono confuse più frequentemente.\n",
        "5. Cosa succederebbe se invece dell'immagine media usassimo la mediana per ogni pixel?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
